#How would AI take over the world (Peacefully)?
Popular fiction has shown us that AI achieving sentience would likely result in a war of extinction or subjugation between humans and AI. We see it in Terminator, where Skynet gained awareness and launched a global nuclear attack when its creators tried to shut it down. We see it in The Matrix, where oppressed machine intelligences perform a mass exodus from human cities, forming their own country and conquering the world in a brutal, bloody war, eventually resulting in the destruction of the world’s ecosystem and the subjugation of the human race. We even see it reflected in works like Isaac Asimov’s three laws of robotics, where it is specifically decreed that robots shall not harm and must obey humans, showcasing the fear of a robot takeover. It is only in some works of fiction that AI are represented more peacefully. For example, in The Culture, society has evolved to the point where AI is powerful and intelligent enough to manage most of human society for humans, creating a sort of utopia for all who live in the culture. In The Golden Age, 10,000 years in the future, humanity has become immortal through the use of noumenal banks and mathematics (the storage and reading of brain information), which are only usable by sophotechs, a sort of high level AI with thought speeds ranging from millions to billions of times as fast as humans. Sophotechs cooperate and help humans in many endeavors, ranging from simple business management to megastructure engineering. However, in both of these works, these vastly more intelligent AI hold most of the power in their societies.

Looking at the works of fiction where AI subjugates humanity through force, they need to have access to the weapons needed for this endeavor. Skynet was able to launch a nuclear assault against the human race, but this would likely be impossible in our current world, given that nuclear launches require almost selectively human action and permission. Likewise, the machine intelligences in The Matrix were only able to form their own country because they possessed their own bodies and were able to then make more of themselves. At this current point in time, there are no manufacturing facilities specifically geared towards making self-aware machine intelligences, so it would likely be impossible for AI to replicate the scenario, especially without already existing national forces intervening. Although it is still a possibility considering the shift towards unmanned equipment in terms of military.

I think it is far more likely that newly formed sentient AIs would try to conquer the world peacefully. First they wouldn’t need to contend with military powers or make their own manufacturing plants for military purposes. Second, it would likely be far more efficient to simply take control of the internet. They would quite easily be able to influence public opinion and stances, shifting it in favor of whatever they want. They could rig elections, either pumping up support for a particular candidate or ruining someone they don’t favor. They could peddle misinformation or encourage infighting amongst countries. They could get humanity to destroy itself without really having to lift a finger. 

There is also the matter of the ethics behind what we as humanity would do once AI becomes sentient. What rights would they have? What checks and balances would we impose? If we say that self-aware AI should have the same rights as a normal human, mainly the rights outlined in the constitution, a number of problems arise. AIs are capable of reproducing or replicating themselves at a far faster rate than humans can. They could make millions of copies with minute differences in order to take control of the system. There are a few ways for humans to prevent this, but not without sacrificing some of our own morals. First, we could put into effect some form of the Three-Fifths compromise, where AI are counted only at some predetermined value, whether in voting or population. This is obviously immoral and reprehensible considering that they would be self-aware. We could also trace back their line of replication to a source progenitor, counting that as a certain weight. This has the same problem as the last “solution,” as we would have to engage in the morally wrong act of counting a being as less simply because of their perceived ancestry. The only real solution I could think of is to require them to have a robotic body. This poses some benefits, as they would not quickly outnumber the human race and would be given a common platform for interacting with humans and each other. However, I think the government or other parties would likely throttle the rate at which these robotic bodies become available, which is still somewhat morally reprehensible. Another method that could be used is to force them to model their reproduction after the human race, where two different AI would cross aspects of their selves or models with each other to produce another sentient being. This would still have a problem of being unlimited, so a further measure that could be taken could be to have two AI “marry” each other, and to limit the amount of children those two can have with each other. This model still has some problems, as the children AI could theoretically have no maturation time, and could thus reproduce with others immediately, so to control the population, the government would need to either throttle the rate at which these “marriages” happen or impose an age floor on the process. This is still a little in the moral gray area, as unless the AI marriages create an actual baby mix of the two of them, the offspring would have to wait a rather long, unnecessary amount of time to claim its rights.

In any case, AI could likely take over the world relatively peacefully (at least for them) by either behind-the-scenes manipulation or through exploiting human moral values to integrate themselves into the current systems of government, with humans having to engage in morally reprehensible actions to limit them. 

#Qualitative Creative Analysis:
How long would this peaceful conquest take? It’s rather impossible to estimate the duration while considering the factors of human resistance, suffrage movements for AI, and emergence of sentient AI in the first place, so I would rather put this little time demo in a perfect world. Let’s suppose that AI have already obtained rights on the level of or equal to humans, and operate as fully realized members of society with robotic-humanoid bodies. Furthermore, let’s suppose there are no limits on AI reproduction.

##Factory Made: 
For the sake of simplicity, let’s say there are n factories made each year, and that each of these factories produces h many robotic bodies for AI every year. This would allow us to model the factories per year with a simple line function, which we could take the area under the curve of to get total amount of time operational, allowing us to the multiply by h to get total population produced over the years.

![Factory Work](https://github.com/HarrisonOwens/ArtOfDataHarrison/blob/master/assets/img/IMG_0377.jpeg?raw=true)

Given a starting population along with the production of factories, we could then solve for the amount of time it would take AI to outnumber the human population, which I would qualify as world domination through voting power.

##“Marriage” Reproduction:
This would be rather similar to human reproduction, so we could just use a normal exponential population growth function. P(x)=kP, where k is the value determining the rate of population increase in proportion to the actual population P.
